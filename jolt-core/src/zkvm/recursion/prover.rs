//! Unified prover for the recursion SNARK protocol
//!
//! This module provides a high-level prover that orchestrates:
//! - Stage 1: Packed GT exp sumcheck
//! - Stage 2: Batched constraint sumchecks (shift + claim reduction + remaining constraints)
//! - Stage 3: Prefix packing reduction to a single dense polynomial opening
//!
//! The prover returns a proof and opening accumulator for PCS verification.

use crate::zkvm::proof_serialization::NonInputBaseHints;
use crate::zkvm::recursion::RecursionConstraintMetadata;
use crate::{
    field::JoltField,
    poly::{
        commitment::{
            commitment_scheme::{CommitmentScheme, RecursionExt},
            dory::{wrappers::ArkDoryProof, ArkworksVerifierSetup, DoryCommitmentScheme},
            hyrax::{matrix_dimensions, Hyrax, HyraxCommitment, PedersenGenerators},
        },
        dense_mlpoly::DensePolynomial,
        multilinear_polynomial::MultilinearPolynomial,
        opening_proof::{OpeningAccumulator, Openings, ProverOpeningAccumulator, SumcheckId},
    },
    transcripts::Transcript,
    zkvm::{
        proof_serialization::PairingBoundary,
        witness::{CommittedPolynomial, VirtualPolynomial},
    },
};
use ark_bn254::{Fq, Fr};
use ark_ff::Zero;
use ark_grumpkin::Projective as GrumpkinProjective;
use ark_serialize::{CanonicalDeserialize, CanonicalSerialize};
use dory::backends::arkworks::ArkGT;
use std::collections::HashMap;

use dory::backends::arkworks::BN254;
use dory::recursion::{ast::AstGraph, WitnessCollection};
use jolt_optimizations::get_g_mle;

use super::{
    constraints::system::{ConstraintSystem, PolyType},
    g1::{
        addition::{G1AddParams, G1AddProver, G1AddProverSpec, G1AddWitness},
        scalar_multiplication::{
            G1ScalarMulConstraintPolynomials, G1ScalarMulParams, G1ScalarMulProver,
            G1ScalarMulProverSpec,
        },
        shift::{g1_shift_params, g2_shift_params, ShiftG1ScalarMulProver, ShiftG2ScalarMulProver},
        WiringG1Prover,
    },
    g2::{
        addition::{G2AddParams, G2AddProver, G2AddProverSpec, G2AddWitness},
        scalar_multiplication::{
            G2ScalarMulConstraintPolynomials, G2ScalarMulParams, G2ScalarMulProver,
            G2ScalarMulProverSpec,
        },
        WiringG2Prover,
    },
    gt::{
        claim_reduction::{GtExpClaimReductionParams, GtExpClaimReductionProver},
        exponentiation::{GtExpParams, GtExpProver},
        fused_exponentiation::{FusedGtExpParams, FusedGtExpProver},
        fused_multiplication::{FusedGtMulParams, FusedGtMulProver},
        fused_shift::{FusedGtShiftParams, FusedGtShiftProver},
        fused_stage2_openings::FusedGtExpStage2OpeningsProver,
        indexing::k_gt,
        multiplication::{GtMulConstraintPolynomials, GtMulParams, GtMulProver, GtMulProverSpec},
        shift::{GtShiftParams, GtShiftProver},
        wiring_binding::GtWiringBindingProver,
        WiringGtProver,
    },
    virtualization::extract_virtual_claims_from_accumulator,
    wiring_plan::derive_wiring_plan,
    witness_generation,
};
use crate::poly::commitment::dory::recursion::JoltWitness;
use crate::poly::rlc_utils::compute_rlc_coefficients;
use crate::subprotocols::sumcheck::{BatchedSumcheck, SumcheckInstanceProof};
use crate::subprotocols::sumcheck_prover::SumcheckInstanceProver;
use crate::zkvm::guest_serde::{GuestDeserialize, GuestSerialize};
use crate::zkvm::recursion::prefix_packing::{packed_eval_from_claims, PrefixPackingLayout};
use crate::zkvm::recursion::witness::GTCombineWitness;

#[cfg(feature = "experimental-pairing-recursion")]
use super::pairing::{
    multi_miller_loop::{MultiMillerLoopParams, MultiMillerLoopProver, MultiMillerLoopProverSpec},
    shift::{ShiftMultiMillerLoopParams, ShiftMultiMillerLoopProver},
};

/// Proof generated by the recursion SNARK
#[derive(Clone, Debug, CanonicalSerialize, CanonicalDeserialize)]
pub struct RecursionProof<F: JoltField, T: Transcript, PCS: CommitmentScheme<Field = F>> {
    /// Stage 1: Packed GT exp sumcheck proof
    pub stage1_proof: SumcheckInstanceProof<F, T>,
    /// Stage 2: Batched constraint sumchecks proof.
    ///
    /// Includes:
    /// - packed-GT-exp internal consistency (shift rho)
    /// - packed-GT-exp claim reduction to a shared `r_x`
    /// - all other constraint families (GT mul, G1/G2 scalar mul, G1/G2 add, ...)
    pub stage2_proof: SumcheckInstanceProof<F, T>,
    /// Stage 3: Prefix-packed evaluation claim \(F(r_x \| r_{\mathrm{pack}})\).
    pub stage3_packed_eval: F,
    /// PCS opening proof for the constraint matrix
    pub opening_proof: PCS::Proof,
    /// Opening claims for virtual polynomials
    pub opening_claims: Openings<F>,
    /// Dense polynomial commitment after Stage 3 prefix packing.
    pub dense_commitment: PCS::Commitment,
}

impl<F, T, PCS> GuestSerialize for RecursionProof<F, T, PCS>
where
    F: JoltField + GuestSerialize,
    F::Challenge: GuestSerialize,
    PCS: CommitmentScheme<Field = F>,
    PCS::Proof: GuestSerialize,
    PCS::Commitment: GuestSerialize,
    T: Transcript,
{
    fn guest_serialize<W: std::io::Write>(&self, w: &mut W) -> std::io::Result<()> {
        self.stage1_proof.guest_serialize(w)?;
        self.stage2_proof.guest_serialize(w)?;
        self.stage3_packed_eval.guest_serialize(w)?;
        self.opening_proof.guest_serialize(w)?;
        self.opening_claims.guest_serialize(w)?;
        self.dense_commitment.guest_serialize(w)?;
        Ok(())
    }
}

impl<F, T, PCS> GuestDeserialize for RecursionProof<F, T, PCS>
where
    F: JoltField + GuestDeserialize,
    F::Challenge: GuestDeserialize,
    PCS: CommitmentScheme<Field = F>,
    PCS::Proof: GuestDeserialize,
    PCS::Commitment: GuestDeserialize,
    T: Transcript,
{
    fn guest_deserialize<R: std::io::Read>(r: &mut R) -> std::io::Result<Self> {
        Ok(Self {
            stage1_proof: SumcheckInstanceProof::<F, T>::guest_deserialize(r)?,
            stage2_proof: SumcheckInstanceProof::<F, T>::guest_deserialize(r)?,
            stage3_packed_eval: F::guest_deserialize(r)?,
            opening_proof: PCS::Proof::guest_deserialize(r)?,
            opening_claims: crate::poly::opening_proof::Openings::<F>::guest_deserialize(r)?,
            dense_commitment: PCS::Commitment::guest_deserialize(r)?,
        })
    }
}

/// Result type for recursion proof generation.
///
/// Contains the proof and constraint metadata needed by the verifier.
pub type RecursionProofResult<T, PCS> =
    Result<(RecursionProof<Fq, T, PCS>, RecursionConstraintMetadata), Box<dyn std::error::Error>>;

// -----------------------------------------------------------------------------
// Internal phase outputs (private helpers for RecursionProver refactor)
// -----------------------------------------------------------------------------

pub(crate) type HyraxPCS = Hyrax<1, GrumpkinProjective>;

pub(crate) struct HyraxPolyCommitPhaseOutput {
    pub(crate) metadata: RecursionConstraintMetadata,
    pub(crate) dense_commitment: HyraxCommitment<1, GrumpkinProjective>,
    pub(crate) dense_mlpoly: MultilinearPolynomial<Fq>,
}

pub(crate) struct SumcheckPhaseOutput<T: Transcript> {
    pub(crate) stage1_proof: SumcheckInstanceProof<Fq, T>,
    pub(crate) stage2_proof: SumcheckInstanceProof<Fq, T>,
    pub(crate) stage3_packed_eval: Fq,
    pub(crate) accumulator: ProverOpeningAccumulator<Fq>,
}

/// Unified prover for the recursion SNARK
#[derive(Clone)]
pub struct RecursionProver<F: JoltField = Fq> {
    /// The constraint system containing all constraints and witness data
    pub constraint_system: ConstraintSystem,
    /// Cached prefix-packed dense polynomial (emitted from stores).
    pub(crate) dense_poly_cache: Option<DensePolynomial<Fq>>,
    /// Cached prefix-packing layout (publicly derivable from `constraint_types`).
    pub(crate) prefix_layout_cache: Option<PrefixPackingLayout>,
    /// AST graph for wiring constraints (optional, only present when using AST-enabled mode)
    pub ast: Option<AstGraph<BN254>>,
    /// Pairing boundary outputs (bound by wiring/boundary constraints once enabled).
    pub pairing_boundary: Option<PairingBoundary>,
    /// Stage-8 joint commitment value (Fq12), bound to combine-commitments GT ops once wiring is enabled.
    pub joint_commitment: Option<ark_bn254::Fq12>,
    /// Number of leaf commitments in the Stage-8 combine DAG.
    pub combine_leaves: usize,
    /// Phantom for field type
    _marker: std::marker::PhantomData<F>,
}

/// Recursion-agnostic snapshot of the Stage 8 (Dory) opening state needed to kick off recursion proving.
///
/// This is produced by Stage 8 (batch opening proof) without performing any recursion-only work.
///
/// CRITICAL transcript invariant:
/// - `pre_opening_proof_transcript` must be forked from the main transcript **after** all Stage 8
///   claims have been appended and gamma has been sampled, but **before** `PCS::prove` mutates
///   the main transcript. This fork is what `PCS::witness_gen` must use (it mutates transcripts).
#[derive(Clone)]
pub struct DoryOpeningSnapshot<F: JoltField, ProofTranscript: Transcript> {
    /// Forked transcript state right after gamma sampling (before `PCS::prove`).
    pub pre_opening_proof_transcript: ProofTranscript,
    /// Unified opening point (big-endian challenges).
    pub opening_point: Vec<<F as JoltField>::Challenge>,
    /// Ordered (polynomial, claim) pairs used for Stage 8 RLC (with any embedding factors applied).
    ///
    /// Order matters: this must match the claim ordering used to sample gamma powers.
    pub polynomial_claims: Vec<(CommittedPolynomial, F)>,
    /// Gamma powers sampled from the transcript after appending all claims.
    pub gamma_powers: Vec<F>,
    /// Joint claim: Σ γ_i · claim_i.
    pub joint_claim: F,
}

/// Bundle of Stage 8 artifacts needed to start recursion proving.
///
/// This removes parameter sprawl at the Stage8→recursion boundary and makes it harder
/// to accidentally desynchronize proof/setup/snapshot inputs.
pub struct RecursionInput<'a, F: JoltField, PCS: RecursionExt<F>, ProofTranscript: Transcript> {
    pub joint_opening_proof: &'a PCS::Proof,
    pub stage8_snapshot: DoryOpeningSnapshot<F, ProofTranscript>,
    pub verifier_setup: &'a PCS::VerifierSetup,
    pub commitments: &'a HashMap<CommittedPolynomial, PCS::Commitment>,
}

impl RecursionProver<Fq> {
    /// Phase 1: witness generation for recursion proving.
    ///
    /// Performs all recursion-only work needed to start recursion proving from the Stage 8 (Dory) opening:
    /// - combine witness generation (Stage 8 offload) + serialized `stage8_combine_hint`
    /// - `PCS::witness_gen_with_ast` (Stage 9) + symbolic AST capture
    /// - build the recursion constraint system and return `RecursionProver`
    #[allow(clippy::type_complexity)]
    #[tracing::instrument(skip_all, name = "RecursionProver::witness_generation")]
    fn witness_generation<F, PCS, ProofTranscript>(
        input: RecursionInput<'_, F, PCS, ProofTranscript>,
    ) -> Result<
        (
            Self,
            ark_bn254::Fq12,
            PCS::Ast,
            PairingBoundary,
            NonInputBaseHints,
        ),
        Box<dyn std::error::Error>,
    >
    where
        F: JoltField,
        PCS: RecursionExt<F, Witness = WitnessCollection<JoltWitness>, Ast = AstGraph<BN254>>,
        ProofTranscript: Transcript,
        PCS::CombineHint: Send,
    {
        let joint_opening_proof = input.joint_opening_proof;
        let verifier_setup = input.verifier_setup;

        // Stage 8 (recursion-only): compute joint commitment (value-only).
        let DoryOpeningSnapshot {
            pre_opening_proof_transcript,
            opening_point,
            polynomial_claims,
            gamma_powers,
            joint_claim,
        } = input.stage8_snapshot;

        let rlc_map = compute_rlc_coefficients(&gamma_powers, polynomial_claims);

        let mut coeffs = Vec::with_capacity(rlc_map.len());
        let mut comms = Vec::with_capacity(rlc_map.len());
        for (poly, coeff) in rlc_map.into_iter() {
            let commitment = input
                .commitments
                .get(&poly)
                .ok_or_else(|| format!("Missing commitment for Stage 8 polynomial {poly:?}"))?;
            coeffs.push(coeff);
            comms.push(commitment.clone());
        }

        let joint_commitment = PCS::combine_commitments(&comms, &coeffs);

        // Phase E3: overlap combine-witness generation with Stage 9 witness generation.
        //
        // Both are expensive but independent once `joint_commitment` is known.
        let (combine_out, witness_out) = rayon::join(
            || {
                tracing::info_span!(
                    "stage8_generate_combine_witness",
                    num_commitments = comms.len()
                )
                .in_scope(|| PCS::generate_combine_witness(&comms, &coeffs))
            },
            || {
                let mut witness_gen_transcript = pre_opening_proof_transcript;
                tracing::info_span!(
                    "stage9_witness_gen_with_ast",
                    opening_point_len = opening_point.len()
                )
                .in_scope(|| {
                    PCS::witness_gen_with_ast(
                        joint_opening_proof,
                        verifier_setup,
                        &mut witness_gen_transcript,
                        &opening_point,
                        &joint_claim,
                        &joint_commitment,
                    )
                })
            },
        );

        let (combine_witness, combine_hint) = combine_out;
        let stage8_combine_hint_fq12 = PCS::combine_hint_to_fq12(&combine_hint);
        let (witness_collection, ast) =
            witness_out.map_err(|e| Box::new(e) as Box<dyn std::error::Error>)?;

        // Phase F (pairing boundary): derive boundary from the (fully realized) AST and Stage 8 inputs.
        //
        // This is later re-derived by the verifier from a symbolic AST for binding.
        let pairing_boundary = PCS::derive_pairing_boundary_from_ast(
            &ast,
            joint_opening_proof,
            verifier_setup,
            joint_commitment,
            &comms,
            &coeffs,
        )
        .map_err(|_e| {
            std::io::Error::new(
                std::io::ErrorKind::InvalidData,
                "AST->pairing-boundary derivation failed",
            )
        })?;

        // Build constraint system from generated witnesses and include combine witness constraints.
        let mut prover = Self::new_from_witnesses(&witness_collection, Some(combine_witness))?;
        prover.pairing_boundary = Some(pairing_boundary.clone());
        prover.joint_commitment = Some(stage8_combine_hint_fq12);

        // Non-input base/point hints for verifier-side instance-plan derivation (perf-only until wiring is added).
        let non_input_base_hints =
            tracing::info_span!("derive_non_input_base_hints").in_scope(|| {
                use dory::recursion::ast::AstOp;
                use dory::recursion::OpId;

                // Collect op lists in OpId order (must match verifier derivation).
                let mut gt_exp: Vec<(OpId, dory::recursion::ast::ValueId)> = Vec::new();
                let mut g1_smul: Vec<(OpId, dory::recursion::ast::ValueId)> = Vec::new();
                let mut g2_smul: Vec<(OpId, dory::recursion::ast::ValueId)> = Vec::new();
                for node in &ast.nodes {
                    match &node.op {
                        AstOp::GTExp {
                            op_id: Some(id),
                            base,
                            ..
                        } => gt_exp.push((*id, *base)),
                        AstOp::G1ScalarMul {
                            op_id: Some(id),
                            point,
                            ..
                        } => g1_smul.push((*id, *point)),
                        AstOp::G2ScalarMul {
                            op_id: Some(id),
                            point,
                            ..
                        } => g2_smul.push((*id, *point)),
                        _ => {}
                    }
                }
                gt_exp.sort_by_key(|(id, _)| *id);
                g1_smul.sort_by_key(|(id, _)| *id);
                g2_smul.sort_by_key(|(id, _)| *id);

                let is_input = |vid: dory::recursion::ast::ValueId| -> bool {
                    let idx = vid.0 as usize;
                    idx < ast.nodes.len() && matches!(ast.nodes[idx].op, AstOp::Input { .. })
                };

                let gt_exp_base_hints = gt_exp
                    .iter()
                    .map(|(op_id, base_id)| {
                        if is_input(*base_id) {
                            None
                        } else {
                            Some(
                                witness_collection
                                    .gt_exp
                                    .get(op_id)
                                    .expect("missing GTExp witness for op_id")
                                    .base,
                            )
                        }
                    })
                    .collect();
                let g1_scalar_mul_base_hints = g1_smul
                    .iter()
                    .map(|(op_id, point_id)| {
                        if is_input(*point_id) {
                            None
                        } else {
                            Some(
                                witness_collection
                                    .g1_scalar_mul
                                    .get(op_id)
                                    .expect("missing G1ScalarMul witness for op_id")
                                    .point_base,
                            )
                        }
                    })
                    .collect();
                let g2_scalar_mul_base_hints = g2_smul
                    .iter()
                    .map(|(op_id, point_id)| {
                        if is_input(*point_id) {
                            None
                        } else {
                            Some(
                                witness_collection
                                    .g2_scalar_mul
                                    .get(op_id)
                                    .expect("missing G2ScalarMul witness for op_id")
                                    .point_base,
                            )
                        }
                    })
                    .collect();

                NonInputBaseHints {
                    gt_exp_base_hints,
                    g1_scalar_mul_base_hints,
                    g2_scalar_mul_base_hints,
                }
            });

        Ok((
            prover,
            stage8_combine_hint_fq12,
            ast,
            pairing_boundary,
            non_input_base_hints,
        ))
    }

    /// Full Stage8→recursion pipeline entrypoint.
    ///
    /// This is the definitive call for recursion proving:
    /// 1) `witness_generation` (Stage 8 offload + Stage 9 `witness_gen` + build CS)\n
    /// 2) `poly_commit` (Hyrax commit)\n
    /// 3) `prove_sumchecks` (all recursion sumchecks)\n
    /// 4) `poly_opening` (Hyrax opening)\n
    ///
    /// Returns the recursion proof and internal verifier metadata.
    #[allow(clippy::type_complexity)]
    pub fn prove<F, DoryPCS, ProofTranscript>(
        transcript: &mut ProofTranscript,
        hyrax_prover_setup: &PedersenGenerators<GrumpkinProjective>,
        input: RecursionInput<'_, F, DoryPCS, ProofTranscript>,
    ) -> Result<
        (
            RecursionProof<Fq, ProofTranscript, HyraxPCS>,
            RecursionConstraintMetadata,
            PairingBoundary,
            Option<ark_bn254::Fq12>,
            NonInputBaseHints,
        ),
        Box<dyn std::error::Error>,
    >
    where
        F: JoltField,
        DoryPCS: RecursionExt<F, Witness = WitnessCollection<JoltWitness>, Ast = AstGraph<BN254>>,
        DoryPCS::CombineHint: Send,
        ProofTranscript: Transcript,
    {
        // Phase 1: witness generation
        let (mut prover, stage8_combine_hint_fq12, ast, pairing_boundary, non_input_base_hints) =
            Self::witness_generation::<F, DoryPCS, ProofTranscript>(input)?;
        prover.ast = Some(ast);

        // Phase 2: polynomial commitment (Hyrax)
        let poly_commit = prover.poly_commit::<ProofTranscript>(transcript, hyrax_prover_setup)?;

        // Phase 3: sumchecks
        let sumchecks =
            prover.prove_sumchecks::<ProofTranscript>(transcript, &poly_commit.metadata)?;

        // Phase 4: polynomial opening (Hyrax)
        let (opening_proof, opening_claims) = Self::poly_opening::<ProofTranscript, HyraxPCS>(
            transcript,
            hyrax_prover_setup,
            sumchecks.accumulator,
            poly_commit.dense_mlpoly,
        )?;

        let proof = RecursionProof {
            stage1_proof: sumchecks.stage1_proof,
            stage2_proof: sumchecks.stage2_proof,
            stage3_packed_eval: sumchecks.stage3_packed_eval,
            opening_proof,
            opening_claims,
            dense_commitment: poly_commit.dense_commitment,
        };

        Ok((
            proof,
            poly_commit.metadata,
            pairing_boundary,
            Some(stage8_combine_hint_fq12),
            non_input_base_hints,
        ))
    }

    /// Create a new recursion prover from pre-generated witnesses
    pub fn new_from_witnesses(
        witness_collection: &WitnessCollection<JoltWitness>,
        combine_witness: Option<GTCombineWitness>,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        tracing::debug!(
            "Creating RecursionProver from witnesses: GT exp count = {}, GT mul count = {}",
            witness_collection.gt_exp.len(),
            witness_collection.gt_mul.len()
        );

        // Compute g_poly directly (was previously computed in witnesses_to_dory_recursion)
        // g(x) is the irreducible polynomial defining the Fq12 extension field
        let g_poly = {
            let g_mle_4var = get_g_mle();
            // Keep `g(x)` in its native 4-var form (size 16). Any embeddings are handled
            // locally by the specific constraint family.
            DensePolynomial::new(g_mle_4var)
        };

        // Build constraint system from witness collection using DoryMatrixBuilder
        let build_cs_span = tracing::info_span!("build_constraint_system").entered();
        let constraint_system =
            Self::build_constraint_system(witness_collection, combine_witness.as_ref(), g_poly)?;
        drop(build_cs_span);

        Ok(Self {
            constraint_system,
            dense_poly_cache: None,
            prefix_layout_cache: None,
            ast: None,
            pairing_boundary: None,
            joint_commitment: None,
            combine_leaves: combine_witness
                .as_ref()
                .map(|cw| cw.exp_witnesses.len())
                .unwrap_or(0),
            _marker: std::marker::PhantomData,
        })
    }

    /// Create a new recursion prover by generating witnesses from a Dory proof
    pub fn new_from_dory_proof<T: Transcript>(
        dory_proof: &ArkDoryProof,
        verifier_setup: &ArkworksVerifierSetup,
        transcript: &mut T,
        point: &[<Fr as JoltField>::Challenge],
        evaluation: &Fr,
        commitment: &ArkGT,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        // Use Dory's witness_gen to generate witnesses
        let (witness_collection, _ast) = DoryCommitmentScheme::witness_gen_with_ast(
            dory_proof,
            verifier_setup,
            transcript,
            point,
            evaluation,
            commitment,
        )?;

        // Delegate to new_from_witnesses (no combine_witness from direct Dory proof)
        Self::new_from_witnesses(&witness_collection, None)
    }

    /// Create a new recursion prover with AST tracing enabled.
    ///
    /// This captures the full computation DAG, enabling:
    /// Build constraint system from recursion witness
    fn build_constraint_system(
        witness_collection: &WitnessCollection<JoltWitness>,
        combine_witness: Option<&GTCombineWitness>,
        g_poly: DensePolynomial<Fq>,
    ) -> Result<ConstraintSystem, Box<dyn std::error::Error>> {
        witness_generation::plan_constraint_system(witness_collection, combine_witness, g_poly)
    }
}

impl RecursionProver<Fq> {
    #[tracing::instrument(skip_all, name = "RecursionProver::poly_commit")]
    pub(crate) fn poly_commit<T: Transcript>(
        &mut self,
        transcript: &mut T,
        prover_setup: &PedersenGenerators<GrumpkinProjective>,
    ) -> Result<HyraxPolyCommitPhaseOutput, Box<dyn std::error::Error>> {
        // ============ EMIT PREFIX-PACKED DENSE POLYNOMIAL ============
        // IMPORTANT: Commitment must happen BEFORE sumchecks for soundness!
        if self.dense_poly_cache.is_none() || self.prefix_layout_cache.is_none() {
            let (dense_poly, prefix_layout) = tracing::info_span!("emit_prefix_packed_dense")
                .in_scope(|| {
                    tracing::info!("Emitting prefix-packed dense polynomial");
                    witness_generation::emit_dense(&self.constraint_system)
                });
            self.dense_poly_cache = Some(dense_poly);
            self.prefix_layout_cache = Some(prefix_layout);
        }

        let dense_poly = self
            .dense_poly_cache
            .as_ref()
            .expect("dense_poly_cache must be populated");
        let prefix_layout = self
            .prefix_layout_cache
            .as_ref()
            .expect("prefix_layout_cache must be populated");

        let dense_num_vars = prefix_layout.num_dense_vars;
        let unpadded_len = prefix_layout.unpadded_len();
        let padded_len = dense_poly.len();

        // Extra diagnostics for GT-fused end-to-end mode: the packed dense polynomial size can
        // jump due to GT-local padding (`num_gt_constraints_padded`) and GTMul's 4->11 var lift.
        //
        // NOTE: Keep this at `info` so it can be enabled via `RUST_LOG=jolt_core=info`.
        let enable_gt_fused_end_to_end = std::env::var("JOLT_RECURSION_ENABLE_GT_FUSED_END_TO_END")
            .ok()
            .map(|v| v != "0" && v.to_lowercase() != "false")
            .unwrap_or(false);
        if enable_gt_fused_end_to_end {
            use crate::zkvm::recursion::gt::indexing::{
                k_gt, num_gt_constraints, num_gt_constraints_padded,
            };
            let num_constraints = self.constraint_system.constraint_types.len();
            let num_gt_exp_ops = self.constraint_system.gt_exp_witnesses.len();
            let num_gt_mul_ops = self.constraint_system.gt_mul_rows.len();
            let num_gt = num_gt_constraints(&self.constraint_system.constraint_types);
            let num_gt_padded = num_gt_constraints_padded(&self.constraint_system.constraint_types);
            let k = k_gt(&self.constraint_system.constraint_types);
            tracing::info!(
                num_constraints,
                num_gt_exp_ops,
                num_gt_mul_ops,
                num_gt_constraints = num_gt,
                num_gt_constraints_padded = num_gt_padded,
                k_gt = k,
                dense_num_vars,
                unpadded_len,
                padded_len,
                "GT-fused prefix packing stats"
            );
            for e in prefix_layout.entries.iter().filter(|e| e.is_gt_fused) {
                tracing::info!(
                    ?e.poly_type,
                    e.num_vars,
                    native_size = (1usize << e.num_vars),
                    e.offset,
                    "GT-fused packed entry"
                );
            }
        }

        // Log how much Hyrax work we skip by avoiding padded zeros.
        let (l_size, r_size) = matrix_dimensions(dense_num_vars, 1);
        debug_assert_eq!(l_size * r_size, padded_len);
        let used_rows = unpadded_len.div_ceil(r_size);
        let skipped_rows = l_size.saturating_sub(used_rows);
        tracing::info!(
            dense_num_vars,
            unpadded_len,
            padded_len,
            r_size,
            l_size,
            used_rows,
            skipped_rows,
            tail_elems = (unpadded_len % r_size),
            "Hyrax commit skipping zero-padded tail"
        );

        // ============ BUILD METADATA (for verifier) ============
        let metadata = tracing::info_span!("build_constraint_metadata").in_scope(|| {
            tracing::info!("Building constraint metadata for verifier");
            let constraint_types = self.constraint_system.constraint_types.clone();

            RecursionConstraintMetadata {
                constraint_types,
                dense_num_vars,
                gt_exp_public_inputs: self.constraint_system.gt_exp_public_inputs.clone(),
                g1_scalar_mul_public_inputs: self
                    .constraint_system
                    .g1_scalar_mul_public_inputs
                    .clone(),
                g2_scalar_mul_public_inputs: self
                    .constraint_system
                    .g2_scalar_mul_public_inputs
                    .clone(),
            }
        });

        // Hyrax commit (optimized): avoid MSM work on zero-padded suffix.
        let dense_commitment = HyraxCommitment::<1, GrumpkinProjective>::commit_with_unpadded_len(
            dense_poly,
            prover_setup,
            unpadded_len,
        );

        // Convert to multilinear polynomial for downstream sumchecks / opening proof.
        let dense_mlpoly = MultilinearPolynomial::from(dense_poly.evals());
        tracing::info!(
            "Hyrax commitment terms: {}, unpadded_len: {}",
            dense_mlpoly.len(),
            unpadded_len
        );

        // Add commitment to transcript for Fiat-Shamir soundness
        transcript.append_serializable(&dense_commitment);

        Ok(HyraxPolyCommitPhaseOutput {
            metadata,
            dense_commitment,
            dense_mlpoly,
        })
    }

    #[tracing::instrument(skip_all, name = "RecursionProver::prove_sumchecks")]
    pub(crate) fn prove_sumchecks<T: Transcript>(
        &mut self,
        transcript: &mut T,
        metadata: &RecursionConstraintMetadata,
    ) -> Result<SumcheckPhaseOutput<T>, Box<dyn std::error::Error>> {
        // ============ RUN ALL SUMCHECKS ============
        // Initialize opening accumulator
        let log_t = self.constraint_system.num_vars();
        let mut accumulator = tracing::info_span!("init_opening_accumulator").in_scope(|| {
            let acc = ProverOpeningAccumulator::<Fq>::new(log_t);
            tracing::info!("Initialized opening accumulator with {} variables", log_t);
            acc
        });

        // Stage 1: Packed GT exp sumcheck
        let (stage1_proof, _r_stage1_packed) = self
            .prove_stage1(transcript, &mut accumulator)
            .expect("Failed to run Stage 1 (GtExp)");

        // Stage 2: Batched constraint sumchecks
        let (stage2_proof, r_stage2) = self
            .prove_stage2(transcript, &mut accumulator)
            .expect("Failed to run Stage 2 (constraint sumchecks)");

        // Stage 2 challenges layout:
        // - legacy: r_stage2 = r_x (length = num_constraint_vars)
        // - fused:  r_stage2 includes extra index variables `r_c` (length >= num_constraint_vars + k)
        //
        // NOTE: Recursion constraint sumchecks are **suffix-aligned** in the batched sumcheck
        // (`round_offset = max_num_rounds - num_rounds`), so shorter points are suffixes of longer
        // ones in the batched challenge order. We therefore interpret `r_x` as the **suffix** of
        // the Stage-2 challenge vector.
        let num_constraint_vars = self.constraint_system.num_constraint_vars();
        if r_stage2.len() < num_constraint_vars {
            return Err(format!(
                "Stage 2 returned {} challenges, expected at least {} (num_constraint_vars)",
                r_stage2.len(),
                num_constraint_vars,
            )
            .into());
        }
        // Interpret `r_x` as the suffix of length `num_constraint_vars`.
        let r_x_start = r_stage2.len() - num_constraint_vars;
        let _r_x = &r_stage2[r_x_start..];
        // If the Stage-2 point contains the GT-local `c_gt` suffix (length k_gt), it is the slice
        // immediately before `r_x`. Other fused-family suffixes may exist, but are not interpreted here.
        let k = k_gt(&self.constraint_system.constraint_types);
        let _r_c_gt = if r_x_start >= k {
            &r_stage2[r_x_start - k..r_x_start]
        } else {
            &[][..]
        };

        // Stage 3: Prefix packing (direct reduction to a single Hyrax opening)
        let stage3_packed_eval = self
            .prove_stage3_prefix_packing(transcript, &mut accumulator, metadata, &r_stage2)
            .expect("Failed to run Stage 3 (prefix packing)");

        Ok(SumcheckPhaseOutput {
            stage1_proof,
            stage2_proof,
            stage3_packed_eval,
            accumulator,
        })
    }

    #[tracing::instrument(skip_all, name = "RecursionProver::poly_opening")]
    pub(crate) fn poly_opening<T: Transcript, PCS: CommitmentScheme<Field = Fq>>(
        transcript: &mut T,
        prover_setup: &PCS::ProverSetup,
        mut accumulator: ProverOpeningAccumulator<Fq>,
        dense_mlpoly: MultilinearPolynomial<Fq>,
    ) -> Result<(PCS::Proof, Openings<Fq>), Box<dyn std::error::Error>> {
        tracing::info!("Generating PCS opening proof");

        // Create polynomial map for opening proof
        let mut polynomials_map: HashMap<CommittedPolynomial, MultilinearPolynomial<Fq>> =
            HashMap::new();
        polynomials_map.insert(CommittedPolynomial::DoryDenseMatrix, dense_mlpoly);

        // Generate opening proof using PCS
        let opening_proof = accumulator
            .prove_single::<T, PCS>(polynomials_map, prover_setup, transcript)
            .expect("Failed to generate PCS opening proof");

        let opening_claims = accumulator.openings.clone();
        tracing::info!(
            "Generated opening proof with {} claims",
            opening_claims.len()
        );

        Ok((opening_proof, opening_claims))
    }

    /// Run Stage 1: Packed GT exp sumcheck
    #[allow(clippy::type_complexity)]
    #[tracing::instrument(skip_all, name = "RecursionProver::prove_stage1")]
    pub(crate) fn prove_stage1<T: Transcript>(
        &self,
        transcript: &mut T,
        accumulator: &mut ProverOpeningAccumulator<Fq>,
    ) -> Result<
        (
            SumcheckInstanceProof<Fq, T>,
            Vec<<Fq as JoltField>::Challenge>,
        ),
        Box<dyn std::error::Error>,
    > {
        let packed_witnesses = &self.constraint_system.gt_exp_witnesses;
        if packed_witnesses.is_empty() {
            return Err("No GtExp constraints to prove in Stage 1".into());
        }

        let enable_gt_fused_end_to_end = std::env::var("JOLT_RECURSION_ENABLE_GT_FUSED_END_TO_END")
            .ok()
            .map(|v| v != "0" && v.to_lowercase() != "false")
            .unwrap_or(false);

        // Packed GT exp uses layout x * 128 + s (s in low bits), so g needs replication
        // across the step variables.
        fn pad_4var_to_11var_replicated(mle_4var: &[Fq]) -> Vec<Fq> {
            debug_assert_eq!(mle_4var.len(), 16, "Input must be a 4-variable MLE");
            let mut mle_11var = vec![Fq::zero(); 2048];
            // index = x * 128 + s (x in high 4 bits, s in low 7 bits)
            for x in 0..16 {
                let g_x = mle_4var[x];
                for s in 0..128 {
                    mle_11var[x * 128 + s] = g_x;
                }
            }
            mle_11var
        }

        let g_4var: Vec<Fq> = self.constraint_system.g_poly.evals();
        let g_replicated = pad_4var_to_11var_replicated(&g_4var);
        let g_poly_replicated_f = DensePolynomial::new(g_replicated);

        let mut packed_gt_exp_prover: Box<dyn SumcheckInstanceProver<Fq, T>> =
            if enable_gt_fused_end_to_end {
                let params = FusedGtExpParams::from_constraint_types(
                    &self.constraint_system.constraint_types,
                );
                tracing::info!(
                    "[Stage 1] Creating FusedGtExpProver with {} GTExp witnesses",
                    packed_witnesses.len()
                );
                Box::new(FusedGtExpProver::new(
                    params,
                    &self.constraint_system.constraint_types,
                    &self.constraint_system.locator_by_constraint,
                    packed_witnesses,
                    g_poly_replicated_f,
                    transcript,
                ))
            } else {
                let params = GtExpParams::new();
                tracing::info!(
                    "[Stage 1] Creating GtExpProver with {} witnesses",
                    packed_witnesses.len()
                );
                Box::new(GtExpProver::new(
                    params,
                    packed_witnesses,
                    g_poly_replicated_f,
                    transcript,
                ))
            };

        // Run the (single-instance) sumcheck.
        let (proof, r_stage1) =
            BatchedSumcheck::prove(vec![&mut *packed_gt_exp_prover], accumulator, transcript);

        Ok((proof, r_stage1))
    }

    /// Run Stage 2: Batched constraint sumchecks.
    ///
    /// This stage includes:
    /// - packed-GT-exp internal consistency (`GtShift`)
    /// - packed-GT-exp claim reduction to a shared `r_x`
    /// - all remaining constraint families (GT mul, G1/G2 scalar mul, G1/G2 add, ...)
    #[allow(clippy::type_complexity)]
    #[tracing::instrument(skip_all, name = "RecursionProver::prove_stage2")]
    pub(crate) fn prove_stage2<T: Transcript>(
        &self,
        transcript: &mut T,
        accumulator: &mut ProverOpeningAccumulator<Fq>,
    ) -> Result<
        (
            SumcheckInstanceProof<Fq, T>,
            Vec<<Fq as JoltField>::Challenge>, // r_stage2 = [r_c || r_x]
        ),
        Box<dyn std::error::Error>,
    > {
        let env_flag_default = |name: &str, default: bool| -> bool {
            std::env::var(name)
                .ok()
                .map(|v| v != "0" && v.to_lowercase() != "false")
                .unwrap_or(default)
        };
        let enable_shift_rho = env_flag_default("JOLT_RECURSION_ENABLE_SHIFT_RHO", true);
        let enable_shift_g1_scalar_mul =
            env_flag_default("JOLT_RECURSION_ENABLE_SHIFT_G1_SCALAR_MUL", true);
        let enable_shift_g2_scalar_mul =
            env_flag_default("JOLT_RECURSION_ENABLE_SHIFT_G2_SCALAR_MUL", true);
        let enable_claim_reduction = env_flag_default("JOLT_RECURSION_ENABLE_PGX_REDUCTION", true);
        let enable_gt_fused_end_to_end =
            env_flag_default("JOLT_RECURSION_ENABLE_GT_FUSED_END_TO_END", false);
        let enable_g1_scalar_mul_fused_end_to_end = env_flag_default(
            "JOLT_RECURSION_ENABLE_G1_SCALAR_MUL_FUSED_END_TO_END",
            false,
        );
        let enable_wiring = env_flag_default("JOLT_RECURSION_ENABLE_WIRING", true);
        let enable_wiring_gt = env_flag_default("JOLT_RECURSION_ENABLE_WIRING_GT", true);
        let enable_wiring_g1 = env_flag_default("JOLT_RECURSION_ENABLE_WIRING_G1", true);
        let enable_wiring_g2 = env_flag_default("JOLT_RECURSION_ENABLE_WIRING_G2", true);
        #[cfg(feature = "experimental-pairing-recursion")]
        let enable_shift_multi_miller_loop =
            env_flag_default("JOLT_RECURSION_ENABLE_SHIFT_MULTI_MILLER_LOOP", true);

        let mut provers: Vec<Box<dyn SumcheckInstanceProver<Fq, T>>> = Vec::new();

        // ---- Packed GT exp (shift rho + claim reduction) ----
        let num_gt_exp = self.constraint_system.gt_exp_witnesses.len();
        if num_gt_exp > 0 {
            let claim_indices: Vec<usize> = (0..num_gt_exp).collect();

            if enable_gt_fused_end_to_end {
                // In end-to-end GT-fused mode, we want the fused GTExp claim-reduction/openings
                // to be available before the fused shift verifier runs (ordering matters in
                // `BatchedSumcheck::verify`).
                if enable_claim_reduction {
                    let prover = FusedGtExpStage2OpeningsProver::<T>::new(
                        &self.constraint_system.constraint_types,
                        &self.constraint_system.locator_by_constraint,
                        &self.constraint_system.gt_exp_witnesses,
                    );
                    provers.push(Box::new(prover));
                }

                if enable_shift_rho {
                    let params = FusedGtShiftParams::from_constraint_types(
                        &self.constraint_system.constraint_types,
                    );
                    let prover = FusedGtShiftProver::new(
                        params,
                        &self.constraint_system.constraint_types,
                        &self.constraint_system.locator_by_constraint,
                        &self.constraint_system.gt_exp_witnesses,
                        accumulator,
                    );
                    provers.push(Box::new(prover));
                }
            } else {
                if enable_shift_rho {
                    let rho_polys: Vec<MultilinearPolynomial<Fq>> = self
                        .constraint_system
                        .gt_exp_witnesses
                        .iter()
                        .map(|w| MultilinearPolynomial::from(w.rho_packed.clone()))
                        .collect();
                    let shift_params = GtShiftParams::new(num_gt_exp);
                    let shift_prover = GtShiftProver::<Fq, T>::new(
                        shift_params,
                        rho_polys,
                        claim_indices.clone(),
                        accumulator,
                        transcript,
                    );
                    provers.push(Box::new(shift_prover));
                }

                if enable_claim_reduction {
                    let rho_polys: Vec<MultilinearPolynomial<Fq>> = self
                        .constraint_system
                        .gt_exp_witnesses
                        .iter()
                        .map(|w| MultilinearPolynomial::from(w.rho_packed.clone()))
                        .collect();
                    let quotient_polys: Vec<MultilinearPolynomial<Fq>> = self
                        .constraint_system
                        .gt_exp_witnesses
                        .iter()
                        .map(|w| MultilinearPolynomial::from(w.quotient_packed.clone()))
                        .collect();
                    let reduction_params = GtExpClaimReductionParams::new(2 * num_gt_exp);
                    let reduction_prover = GtExpClaimReductionProver::<Fq, T>::new(
                        reduction_params,
                        &claim_indices,
                        rho_polys,
                        quotient_polys,
                        accumulator,
                        transcript,
                    );
                    provers.push(Box::new(reduction_prover));
                }
            }
        }

        // ---- GT mul / G1+G2 scalar mul / G1+G2 add (and any other Stage 2 constraints) ----
        //
        // NOTE: These were previously run in Stage 1; we keep their logic but batch them here.

        // Convert g_poly for GT mul (uses zero padding layout: s * 16 + x)
        let g_poly_f = self.constraint_system.g_poly.clone();

        // GT mul
        let gt_mul_rows = &self.constraint_system.gt_mul_rows;
        if !gt_mul_rows.is_empty() {
            let gt_mul_constraints_fq: Vec<GtMulConstraintPolynomials<Fq>> = gt_mul_rows
                .iter()
                .enumerate()
                .map(|(i, rows)| GtMulConstraintPolynomials {
                    lhs: rows.lhs.clone(),
                    rhs: rows.rhs.clone(),
                    result: rows.result.clone(),
                    quotient: rows.quotient.clone(),
                    constraint_index: i,
                })
                .collect();
            if enable_gt_fused_end_to_end {
                let num_gt_constraints = gt_mul_constraints_fq.len();
                let k_common = crate::zkvm::recursion::gt::indexing::k_gt(
                    &self.constraint_system.constraint_types,
                );
                let num_gt_constraints_padded =
                    crate::zkvm::recursion::gt::indexing::num_gt_mul_constraints_padded(
                        &self.constraint_system.constraint_types,
                    );
                let params =
                    FusedGtMulParams::new(num_gt_constraints, num_gt_constraints_padded, k_common);
                let prover = FusedGtMulProver::new(
                    params,
                    &self.constraint_system.constraint_types,
                    &gt_mul_constraints_fq,
                    &g_poly_f,
                    transcript,
                );
                provers.push(Box::new(prover));
            } else {
                let constraint_indices: Vec<usize> = (0..gt_mul_rows.len()).collect();
                let params = GtMulParams::new(gt_mul_constraints_fq.len());
                let spec = GtMulProverSpec::new(params, gt_mul_constraints_fq, g_poly_f.clone());
                let prover = GtMulProver::from_spec(spec, constraint_indices, transcript);
                provers.push(Box::new(prover));
            }
        }

        // G1 scalar mul
        let g1_rows = &self.constraint_system.g1_scalar_mul_rows;
        if !g1_rows.is_empty() {
            debug_assert_eq!(
                self.constraint_system.g1_scalar_mul_public_inputs.len(),
                g1_rows.len(),
                "ConstraintSystem.g1_scalar_mul_public_inputs must match extracted G1 scalar-mul constraints"
            );

            if enable_g1_scalar_mul_fused_end_to_end {
                // Fused shift check (opens 4 fused polynomials at one point).
                if enable_shift_g1_scalar_mul {
                    let prover =
                        crate::zkvm::recursion::g1::fused_scalar_multiplication::FusedShiftG1ScalarMulProver::new(
                            g1_rows,
                            transcript,
                        );
                    provers.push(Box::new(prover));
                }

                // Fused scalar-mul constraints (opens 8 fused polynomials at one point).
                let prover =
                    crate::zkvm::recursion::g1::fused_scalar_multiplication::FusedG1ScalarMulProver::new(
                        g1_rows,
                        &self.constraint_system.g1_scalar_mul_public_inputs,
                        transcript,
                    );
                provers.push(Box::new(prover));
            } else {
                if enable_shift_g1_scalar_mul {
                    let mut pairs: Vec<(VirtualPolynomial, Vec<Fq>, VirtualPolynomial, Vec<Fq>)> =
                        Vec::with_capacity(g1_rows.len() * 2);

                    for (i, w) in g1_rows.iter().enumerate() {
                        let xa = VirtualPolynomial::g1_scalar_mul_xa(i);
                        let xa_next = VirtualPolynomial::g1_scalar_mul_xa_next(i);
                        pairs.push((xa, w.x_a.clone(), xa_next, w.x_a_next.clone()));

                        let ya = VirtualPolynomial::g1_scalar_mul_ya(i);
                        let ya_next = VirtualPolynomial::g1_scalar_mul_ya_next(i);
                        pairs.push((ya, w.y_a.clone(), ya_next, w.y_a_next.clone()));
                    }

                    let shift_params = g1_shift_params(pairs.len());
                    let shift_prover =
                        ShiftG1ScalarMulProver::<Fq, T>::new(shift_params, pairs, transcript);
                    provers.push(Box::new(shift_prover));
                }

                let mut g1_scalar_mul_constraints: Vec<G1ScalarMulConstraintPolynomials<Fq>> =
                    Vec::with_capacity(g1_rows.len());
                let mut g1_scalar_mul_base_points: Vec<(Fq, Fq)> =
                    Vec::with_capacity(g1_rows.len());

                for (i, w) in g1_rows.iter().enumerate() {
                    g1_scalar_mul_constraints.push(G1ScalarMulConstraintPolynomials {
                        x_a: w.x_a.clone(),
                        y_a: w.y_a.clone(),
                        x_t: w.x_t.clone(),
                        y_t: w.y_t.clone(),
                        x_a_next: w.x_a_next.clone(),
                        y_a_next: w.y_a_next.clone(),
                        t_indicator: w.t_indicator.clone(),
                        a_indicator: w.a_indicator.clone(),
                        constraint_index: i,
                    });
                    g1_scalar_mul_base_points.push(w.base_point);
                }

                let params = G1ScalarMulParams::new(g1_scalar_mul_constraints.len());
                let (spec, constraint_indices) = G1ScalarMulProverSpec::new(
                    params,
                    g1_scalar_mul_constraints,
                    &self.constraint_system.g1_scalar_mul_public_inputs,
                    g1_scalar_mul_base_points,
                );
                let prover = G1ScalarMulProver::from_spec(spec, constraint_indices, transcript);
                provers.push(Box::new(prover));
            }
        }

        // G2 scalar mul
        let g2_rows = &self.constraint_system.g2_scalar_mul_rows;
        if !g2_rows.is_empty() {
            debug_assert_eq!(
                self.constraint_system.g2_scalar_mul_public_inputs.len(),
                g2_rows.len(),
                "ConstraintSystem.g2_scalar_mul_public_inputs must match extracted G2 scalar-mul constraints"
            );

            if enable_shift_g2_scalar_mul {
                let mut pairs: Vec<(VirtualPolynomial, Vec<Fq>, VirtualPolynomial, Vec<Fq>)> =
                    Vec::with_capacity(g2_rows.len() * 4);
                for (i, w) in g2_rows.iter().enumerate() {
                    let xa_c0 = VirtualPolynomial::g2_scalar_mul_xa_c0(i);
                    let xa_next_c0 = VirtualPolynomial::g2_scalar_mul_xa_next_c0(i);
                    pairs.push((xa_c0, w.x_a_c0.clone(), xa_next_c0, w.x_a_next_c0.clone()));

                    let xa_c1 = VirtualPolynomial::g2_scalar_mul_xa_c1(i);
                    let xa_next_c1 = VirtualPolynomial::g2_scalar_mul_xa_next_c1(i);
                    pairs.push((xa_c1, w.x_a_c1.clone(), xa_next_c1, w.x_a_next_c1.clone()));

                    let ya_c0 = VirtualPolynomial::g2_scalar_mul_ya_c0(i);
                    let ya_next_c0 = VirtualPolynomial::g2_scalar_mul_ya_next_c0(i);
                    pairs.push((ya_c0, w.y_a_c0.clone(), ya_next_c0, w.y_a_next_c0.clone()));

                    let ya_c1 = VirtualPolynomial::g2_scalar_mul_ya_c1(i);
                    let ya_next_c1 = VirtualPolynomial::g2_scalar_mul_ya_next_c1(i);
                    pairs.push((ya_c1, w.y_a_c1.clone(), ya_next_c1, w.y_a_next_c1.clone()));
                }

                let shift_params = g2_shift_params(pairs.len());
                let shift_prover =
                    ShiftG2ScalarMulProver::<Fq, T>::new(shift_params, pairs, transcript);
                provers.push(Box::new(shift_prover));
            }

            let mut g2_scalar_mul_constraints: Vec<G2ScalarMulConstraintPolynomials<Fq>> =
                Vec::with_capacity(g2_rows.len());
            let mut g2_scalar_mul_base_points = Vec::with_capacity(g2_rows.len());

            for (i, w) in g2_rows.iter().enumerate() {
                g2_scalar_mul_constraints.push(G2ScalarMulConstraintPolynomials {
                    x_a_c0: w.x_a_c0.clone(),
                    x_a_c1: w.x_a_c1.clone(),
                    y_a_c0: w.y_a_c0.clone(),
                    y_a_c1: w.y_a_c1.clone(),
                    x_t_c0: w.x_t_c0.clone(),
                    x_t_c1: w.x_t_c1.clone(),
                    y_t_c0: w.y_t_c0.clone(),
                    y_t_c1: w.y_t_c1.clone(),
                    x_a_next_c0: w.x_a_next_c0.clone(),
                    x_a_next_c1: w.x_a_next_c1.clone(),
                    y_a_next_c0: w.y_a_next_c0.clone(),
                    y_a_next_c1: w.y_a_next_c1.clone(),
                    t_indicator: w.t_indicator.clone(),
                    a_indicator: w.a_indicator.clone(),
                    constraint_index: i,
                });
                g2_scalar_mul_base_points.push(w.base_point);
            }

            let params = G2ScalarMulParams::new(g2_scalar_mul_constraints.len());
            let (spec, constraint_indices) = G2ScalarMulProverSpec::new(
                params,
                g2_scalar_mul_constraints,
                &self.constraint_system.g2_scalar_mul_public_inputs,
                g2_scalar_mul_base_points,
            );
            let prover = G2ScalarMulProver::from_spec(spec, constraint_indices, transcript);
            provers.push(Box::new(prover));
        }

        // G1 add
        let g1_add_rows = &self.constraint_system.g1_add_rows;
        if !g1_add_rows.is_empty() {
            let g1_add_constraints: Vec<G1AddWitness<Fq>> = g1_add_rows
                .iter()
                .enumerate()
                .map(|(constraint_index, w)| G1AddWitness {
                    x_p: vec![w.x_p],
                    y_p: vec![w.y_p],
                    ind_p: vec![w.ind_p],
                    x_q: vec![w.x_q],
                    y_q: vec![w.y_q],
                    ind_q: vec![w.ind_q],
                    x_r: vec![w.x_r],
                    y_r: vec![w.y_r],
                    ind_r: vec![w.ind_r],
                    lambda: vec![w.lambda],
                    inv_delta_x: vec![w.inv_delta_x],
                    is_double: vec![w.is_double],
                    is_inverse: vec![w.is_inverse],
                    constraint_index,
                })
                .collect();
            // NOTE: The fused G1Add sumcheck exists (see `g1::fused_addition`) but is intentionally
            // NOT wired into the default prover pipeline right now.
            let params = G1AddParams::new(g1_add_constraints.len());
            let (spec, constraint_indices) = G1AddProverSpec::new(params, g1_add_constraints);
            let prover = G1AddProver::from_spec(spec, constraint_indices, transcript);
            provers.push(Box::new(prover));
        }

        // G2 add
        let g2_add_rows = &self.constraint_system.g2_add_rows;
        if !g2_add_rows.is_empty() {
            let g2_add_constraints: Vec<G2AddWitness<Fq>> = g2_add_rows
                .iter()
                .enumerate()
                .map(|(constraint_index, w)| G2AddWitness {
                    x_p_c0: vec![w.x_p_c0],
                    x_p_c1: vec![w.x_p_c1],
                    y_p_c0: vec![w.y_p_c0],
                    y_p_c1: vec![w.y_p_c1],
                    ind_p: vec![w.ind_p],
                    x_q_c0: vec![w.x_q_c0],
                    x_q_c1: vec![w.x_q_c1],
                    y_q_c0: vec![w.y_q_c0],
                    y_q_c1: vec![w.y_q_c1],
                    ind_q: vec![w.ind_q],
                    x_r_c0: vec![w.x_r_c0],
                    x_r_c1: vec![w.x_r_c1],
                    y_r_c0: vec![w.y_r_c0],
                    y_r_c1: vec![w.y_r_c1],
                    ind_r: vec![w.ind_r],
                    lambda_c0: vec![w.lambda_c0],
                    lambda_c1: vec![w.lambda_c1],
                    inv_delta_x_c0: vec![w.inv_delta_x_c0],
                    inv_delta_x_c1: vec![w.inv_delta_x_c1],
                    is_double: vec![w.is_double],
                    is_inverse: vec![w.is_inverse],
                    constraint_index,
                })
                .collect();
            let params = G2AddParams::new(g2_add_constraints.len());
            let (spec, constraint_indices) = G2AddProverSpec::new(params, g2_add_constraints);
            let prover = G2AddProver::from_spec(spec, constraint_indices, transcript);
            provers.push(Box::new(prover));
        }

        // Multi-Miller loop (pairing Miller loop) + shift chaining (experimental)
        #[cfg(feature = "experimental-pairing-recursion")]
        {
            // TODO: wire up pairing recursion native stores in the streaming pipeline.
            let _ = enable_shift_multi_miller_loop;
        }

        // ---- Wiring/boundary constraints (AST-driven), appended LAST in Stage 2 ----
        if enable_wiring {
            if let (Some(ast), Some(pairing_boundary), Some(joint_commitment)) = (
                self.ast.as_ref(),
                self.pairing_boundary.as_ref(),
                self.joint_commitment.as_ref(),
            ) {
                let wiring = derive_wiring_plan(ast, self.combine_leaves, pairing_boundary)
                    .map_err(|_e| "AST->wiring-plan derivation failed")?;

                if enable_wiring_gt && !wiring.gt.is_empty() {
                    if enable_gt_fused_end_to_end {
                        // Fully fused GT wiring backend (no aux sums / no legacy binding check).
                        let wiring_gt =
                            crate::zkvm::recursion::gt::fused_wiring::FusedWiringGtProver::<T>::new(
                                &self.constraint_system,
                                wiring.gt.clone(),
                                pairing_boundary,
                                joint_commitment.clone(),
                                transcript,
                            );
                        provers.push(Box::new(wiring_gt));
                    } else {
                        // Legacy backend (aux sums + binding safety net).
                        let wiring_gt = WiringGtProver::<T>::new(
                            &self.constraint_system,
                            wiring.gt.clone(),
                            pairing_boundary,
                            joint_commitment.clone(),
                            transcript,
                        );
                        // Legacy safety net: bind prover-emitted wiring sums to the actual per-edge
                        // wiring expression.
                        provers.push(Box::new(GtWiringBindingProver::<T>::new(
                            wiring_gt.num_rounds(),
                        )));
                        provers.push(Box::new(wiring_gt));
                    }
                }
                if enable_wiring_g1 && !wiring.g1.is_empty() {
                    provers.push(Box::new(WiringG1Prover::<T>::new(
                        &self.constraint_system,
                        wiring.g1.clone(),
                        pairing_boundary,
                        transcript,
                    )));
                }
                if enable_wiring_g2 && !wiring.g2.is_empty() {
                    provers.push(Box::new(WiringG2Prover::<T>::new(
                        &self.constraint_system,
                        wiring.g2.clone(),
                        pairing_boundary,
                        transcript,
                    )));
                }
            }
        }

        if provers.is_empty() {
            return Err("No constraints to prove in Stage 2".into());
        }

        let (proof, r_stage2) = BatchedSumcheck::prove(
            provers.iter_mut().map(|p| &mut **p as _).collect(),
            accumulator,
            transcript,
        );

        Ok((proof, r_stage2))
    }

    /// Run Stage 3: Prefix packing reduction.
    ///
    /// This samples fresh "packing prefix" challenges and reduces all Stage 2 virtual openings
    /// to a single opening of the packed dense polynomial `CommittedPolynomial::DoryDenseMatrix`.
    #[tracing::instrument(skip_all, name = "RecursionProver::prove_stage3_prefix_packing")]
    pub(crate) fn prove_stage3_prefix_packing<T: Transcript>(
        &mut self,
        transcript: &mut T,
        accumulator: &mut ProverOpeningAccumulator<Fq>,
        metadata: &RecursionConstraintMetadata,
        r_stage2: &[<Fq as JoltField>::Challenge],
    ) -> Result<Fq, Box<dyn std::error::Error>> {
        // Derive the public packing layout.
        let enable_gt_fused_end_to_end = std::env::var("JOLT_RECURSION_ENABLE_GT_FUSED_END_TO_END")
            .ok()
            .map(|v| v != "0" && v.to_lowercase() != "false")
            .unwrap_or(false);
        let enable_g1_scalar_mul_fused_end_to_end =
            std::env::var("JOLT_RECURSION_ENABLE_G1_SCALAR_MUL_FUSED_END_TO_END")
                .ok()
                .map(|v| v != "0" && v.to_lowercase() != "false")
                .unwrap_or(false);
        let layout = if enable_gt_fused_end_to_end || enable_g1_scalar_mul_fused_end_to_end {
            PrefixPackingLayout::from_constraint_types_fused(
                &metadata.constraint_types,
                enable_gt_fused_end_to_end,
                enable_g1_scalar_mul_fused_end_to_end,
            )
        } else {
            PrefixPackingLayout::from_constraint_types(&metadata.constraint_types)
        };
        if layout.num_dense_vars != metadata.dense_num_vars {
            return Err(format!(
                "prefix packing layout mismatch: metadata.dense_num_vars={} but derived layout has {}",
                metadata.dense_num_vars, layout.num_dense_vars
            )
            .into());
        }

        let max_native_vars = layout.entries.iter().map(|e| e.num_vars).max().unwrap_or(0);
        if r_stage2.len() < max_native_vars {
            return Err(format!(
                "Stage 2 produced r_stage2 of length {}, but prefix packing needs at least {} bits",
                r_stage2.len(),
                max_native_vars
            )
            .into());
        }

        // Low variables: Stage-2 point suffix (suffix-aligned Stage 2), **reversed**.
        //
        // Stage 2 constraint sumchecks are suffix-aligned in the batched sumcheck, so an m-var
        // polynomial is opened at the *suffix* of the common challenge vector. For the
        // prefix-packing reduction we want these to appear as prefixes, so we reverse the suffix
        // here.
        let mut r_native_fq: Vec<Fq> = r_stage2[r_stage2.len() - max_native_vars..]
            .iter()
            .map(|c| (*c).into())
            .collect();
        r_native_fq.reverse();

        // High variables: fresh packing challenges.
        let pack_len = layout.num_dense_vars.saturating_sub(max_native_vars);
        let r_pack: Vec<Fq> = (0..pack_len)
            .map(|_| transcript.challenge_scalar::<Fq>())
            .collect();

        // Full packed opening point in little-endian (low-to-high) variable order.
        let mut r_full_lsb: Vec<Fq> = Vec::with_capacity(layout.num_dense_vars);
        r_full_lsb.extend_from_slice(&r_native_fq);
        r_full_lsb.extend_from_slice(&r_pack);

        // Extract Stage 2 virtual claims in the standard [constraint-major, poly-type-minor] layout.
        let virtual_claims = extract_virtual_claims_from_accumulator(
            accumulator,
            &metadata.constraint_types,
            &self.constraint_system.gt_exp_public_inputs,
            enable_gt_fused_end_to_end,
            enable_g1_scalar_mul_fused_end_to_end,
        );
        let num_poly_types = PolyType::NUM_TYPES;

        // Compute packed evaluation claim: F(r) = Σ_i eq(prefix_i, codeword_i) · f_i(r_x_prefix).
        let packed_eval = packed_eval_from_claims(&layout, &r_full_lsb, |entry| {
            if enable_gt_fused_end_to_end && entry.is_gt_fused {
                let (sumcheck, vp) = match entry.poly_type {
                    PolyType::RhoPrev => (
                        SumcheckId::GtExpClaimReduction,
                        VirtualPolynomial::gt_exp_rho_fused(),
                    ),
                    PolyType::Quotient => (
                        SumcheckId::GtExpClaimReduction,
                        VirtualPolynomial::gt_exp_quotient_fused(),
                    ),
                    PolyType::MulLhs => (SumcheckId::GtMul, VirtualPolynomial::gt_mul_lhs_fused()),
                    PolyType::MulRhs => (SumcheckId::GtMul, VirtualPolynomial::gt_mul_rhs_fused()),
                    PolyType::MulResult => {
                        (SumcheckId::GtMul, VirtualPolynomial::gt_mul_result_fused())
                    }
                    PolyType::MulQuotient => (
                        SumcheckId::GtMul,
                        VirtualPolynomial::gt_mul_quotient_fused(),
                    ),
                    _ => return Fq::zero(),
                };
                let (_, claim) = accumulator.get_virtual_polynomial_opening(vp, sumcheck);
                claim
            } else if enable_g1_scalar_mul_fused_end_to_end && entry.is_g1_scalar_mul_fused {
                let vp = match entry.poly_type {
                    PolyType::G1ScalarMulXA => VirtualPolynomial::g1_scalar_mul_xa_fused(),
                    PolyType::G1ScalarMulYA => VirtualPolynomial::g1_scalar_mul_ya_fused(),
                    PolyType::G1ScalarMulXT => VirtualPolynomial::g1_scalar_mul_xt_fused(),
                    PolyType::G1ScalarMulYT => VirtualPolynomial::g1_scalar_mul_yt_fused(),
                    PolyType::G1ScalarMulXANext => VirtualPolynomial::g1_scalar_mul_xa_next_fused(),
                    PolyType::G1ScalarMulYANext => VirtualPolynomial::g1_scalar_mul_ya_next_fused(),
                    PolyType::G1ScalarMulTIndicator => {
                        VirtualPolynomial::g1_scalar_mul_t_indicator_fused()
                    }
                    PolyType::G1ScalarMulAIndicator => {
                        VirtualPolynomial::g1_scalar_mul_a_indicator_fused()
                    }
                    _ => return Fq::zero(),
                };
                let (_, claim) =
                    accumulator.get_virtual_polynomial_opening(vp, SumcheckId::G1ScalarMul);
                claim
            } else {
                let claim_idx = entry.constraint_idx * num_poly_types + (entry.poly_type as usize);
                virtual_claims
                    .get(claim_idx)
                    .copied()
                    .unwrap_or_else(Fq::zero)
            }
        });

        // Append as a Fiat–Shamir message (matches existing Stage 3 transcript pattern).
        transcript.append_scalar(&packed_eval);

        // Register a committed opening on the packed dense polynomial.
        //
        // Opening points are stored in BIG_ENDIAN order for PCS verification.
        let opening_point: Vec<<Fq as JoltField>::Challenge> =
            r_full_lsb.into_iter().rev().map(|f| f.into()).collect();
        accumulator.append_dense(
            transcript,
            CommittedPolynomial::DoryDenseMatrix,
            SumcheckId::RecursionPacked,
            opening_point,
            packed_eval,
        );

        Ok(packed_eval)
    }
}
